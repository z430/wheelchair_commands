{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpeechFeatures.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "6m53nSwyKxBv",
        "colab_type": "code",
        "outputId": "6ff43f4b-02bc-403c-da65-8e48b11f35d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import librosa\n",
        "from keras import optimizers, losses\n",
        "from keras.backend import set_session\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import h5py\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import input_data\n",
        "import numpy as np\n",
        "import dnn_models\n",
        "import random\n",
        "import audio_utility as au\n",
        "import sys\n",
        "\n",
        "r = random.randint(1111, 9999)\n",
        "\n",
        "\n",
        "def data_gen(sess, features_settings, mode='training', batch_size=5):\n",
        "    offset = 0\n",
        "    if mode != 'training':\n",
        "        background_frequency = 0.0\n",
        "        background_volume_range = 0.0\n",
        "        foreground_frequency = 0.0\n",
        "        foreground_volume_range = 0.0\n",
        "        pseudo_frequency = 0.0\n",
        "        time_shift_frequency = 0.0\n",
        "        time_shift_range = [0, 0]\n",
        "    while True:\n",
        "        X, y = features_settings.get_data(\n",
        "            how_many=batch_size, offset=0 if mode == 'training' else offset,\n",
        "            mode=mode)\n",
        "\n",
        "        offset += batch_size\n",
        "        if offset > features_settings.set_size(mode) - batch_size:\n",
        "            offset = 0\n",
        "        yield X, y\n",
        "    \n",
        "\n",
        "def main():\n",
        "\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.per_process_gpu_memory_fraction = 0.7\n",
        "    config.gpu_options.allow_growth = True\n",
        "    set_session(tf.Session(config=config))\n",
        "\n",
        "    \"\"\" ------------------- GET TF SESSION ------------------- \"\"\"\n",
        "    sess = tf.InteractiveSession()\n",
        "\n",
        "    \"\"\" ------------------- Features Configuration ------------------- \"\"\"\n",
        "    wanted_words = 'left,right,forward,backward,stop,go'\n",
        "    speech_feature = 'cgram'\n",
        "    features = input_data.GetData(wanted_words=wanted_words, feature=speech_feature)\n",
        "    # initialize dataset\n",
        "    features.initialize()\n",
        "    model_settings = features.model_settings\n",
        "\n",
        "    sr = random.SystemRandom()\n",
        "    # version number is random every training\n",
        "    version_number = (time.asctime(time.localtime(time.time()))).replace(' ', '_')\n",
        "    \"\"\" ------------------- Model Configuration ------------------- \"\"\"\n",
        "\n",
        "    train_gen = data_gen(sess, features, mode='training')\n",
        "    val_gen = data_gen(sess, features, mode='validation')\n",
        "    test_gen = data_gen(sess, features, mode='testing')\n",
        "\n",
        "    print(features.silence_percentage, features.unknown_percentage)\n",
        "\n",
        "    max_epoch = 1000\n",
        "    learning_rate = 0.0001\n",
        "    decay_rate = learning_rate / max_epoch\n",
        "    opt = optimizers.RMSprop(lr=learning_rate)\n",
        "    model_name = 'cnn'\n",
        "\n",
        "    input_size = features.input_shape\n",
        "    dnn_model = dnn_models.select_model(input_size, model_settings['label_count'],\n",
        "                                        model_name)\n",
        "    dnn_model.compile(\n",
        "        optimizer=opt, loss=losses.categorical_crossentropy,\n",
        "        metrics=[\n",
        "            'accuracy',\n",
        "            'categorical_accuracy'\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    model_name = f\"{version_number}_{speech_feature}_{wanted_words.replace(',', '_')}\"\n",
        "    dnn_model.summary()\n",
        "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "        filepath='models/{}_{}.hdf5'.format(model_name, r),\n",
        "        verbose=1, save_best_only=False,\n",
        "        monitor='val_categorical_accuracy')\n",
        "    model_stop_training = keras.callbacks.EarlyStopping(\n",
        "        monitor='loss', patience=100, verbose=1)\n",
        "    tensorboard = TensorBoard(log_dir='./retrain_logs', histogram_freq=0)\n",
        "    lr_reduce_op = keras.callbacks.ReduceLROnPlateau(\n",
        "        factor=0.01, min_lr=0.00001, monitor='categorical_accuracy')\n",
        "    batch_size = 10\n",
        "\n",
        "    \"\"\" -------------------------------------- train ----------------------------------------------\"\"\"\n",
        "    print(50*'=', 'STAGE 2 TRAINING', 50*'=')\n",
        "    dnn_model.fit_generator(train_gen,\n",
        "                            steps_per_epoch=features.set_size(\n",
        "                                'training')//batch_size,\n",
        "                            epochs=100, verbose=1, callbacks=[\n",
        "                                tensorboard,\n",
        "                                model_checkpoint,\n",
        "                                lr_reduce_op, model_stop_training])\n",
        "\n",
        "    dnn_model.save(f\"models/{model_name}.hdf5\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ">> Downloading speech_commands_v0.02.tar.gz 34.6%Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xaJuxfKxOcq5",
        "colab_type": "code",
        "outputId": "bc72a4e3-410c-4a42-b21f-0b626ffbef94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install speechpy python_speech_features SimpleITK\n",
        "!pip install git+https://github.com/z430/pycochleagram.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting speechpy\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/12/dbda397a998063d9541d9e149c4f523ed138a48824d20598e37632ba33b1/speechpy-2.4-py2.py3-none-any.whl\n",
            "Collecting python_speech_features\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/d1/94c59e20a2631985fbd2124c45177abaa9e0a4eee8ba8a305aa26fc02a8e/python_speech_features-0.6.tar.gz\n",
            "Collecting SimpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/ee/8ddd251cf447e1fc131622e925d538c2542780195ae75e26c122587630d1/SimpleITK-1.2.0-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 42.5MB 811kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from speechpy) (1.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from speechpy) (1.16.3)\n",
            "Building wheels for collected packages: python-speech-features\n",
            "  Building wheel for python-speech-features (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3c/42/7c/f60e9d1b40015cd69b213ad90f7c18a9264cd745b9888134be\n",
            "Successfully built python-speech-features\n",
            "Installing collected packages: speechpy, python-speech-features, SimpleITK\n",
            "Successfully installed SimpleITK-1.2.0 python-speech-features-0.6 speechpy-2.4\n",
            "Collecting git+https://github.com/z430/pycochleagram.git\n",
            "  Cloning https://github.com/z430/pycochleagram.git to /tmp/pip-req-build-k6qbzhew\n",
            "Building wheels for collected packages: pycochleagram\n",
            "  Building wheel for pycochleagram (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-_t_mbzho/wheels/61/88/37/59638e4f8458e442e41b336ff46d1539fccc4eab08d5d1e243\n",
            "Successfully built pycochleagram\n",
            "Installing collected packages: pycochleagram\n",
            "Successfully installed pycochleagram-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}